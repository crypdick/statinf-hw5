---
title: "Homework 5"
author: "Statistical Inference 1"
date: "11/22/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
require(ggplot2)
```


# Guidelines

+ This is a group project. You may work in groups with up to 6 people. You only need to turn in one homework assignment for each group, but make sure that everyone’s name is listed on the assignment. 
+ Also, even if you don’t write the code for every part of the assignment, you should practice the skills in each section.
+ This assignment focuses on simulating data that violates various assumptions of the linear regression model.
+ Some sample code has been included, but you will need to try many different starting values for the parameters, sample size, and distributional assumptions. The included code is just to give you a starting point; it should not be considered sufficient to answer all the questions in each part. (And you are welcome to ignore the sample code and use your own)

```{r run_sim}
check_violations <- function(sample_size, orig_new_obsv, violation_name, violation_func, sigma_sq, orig_X) {

  # ordinary relationship with no violations of linearity
  if (violation_name == "None") {
    X <- orig_X
    new_obsv <- orig_new_obsv
    eps <- rnorm(sample_size, mean = 0, sd = sqrt(sigma_sq))
    return(list(X,new_obsv,eps))
  }
  if (violation_name == "Nonlinear relationship") {
    X <- violation_func(orig_X)
    new_obsv <- violation_func(orig_new_obsv)
    eps <- rnorm(sample_size, mean = 0, sd = sqrt(sigma_sq))
    return(list(X,new_obsv,eps))
  }
  if (violation_name == "Non-normal errors") {
    # gamma distributed errors
    if (violation_func == "Gamma") {
      X <- orig_X
      new_obsv <- orig_new_obsv
      eps_alpha <- 2
      eps_beta <- 1/4
      eps <- (rgamma(sample_size, shape = eps_alpha, scale = eps_beta) - eps_alpha * eps_beta) * 2
      return(list(X,new_obsv,eps))
    }
    # poisson distributed errors
    if (violation_func == "Poisson") {
      X <- orig_X
      new_obsv <- orig_new_obsv
      lambda <- 4
      eps <- (rpois(sample_size, lambda) - lambda) * 2
      return(list(X,new_obsv,eps))
    }
  }
  if (violation_name == "Heterogeneous variances") {
    X <- orig_X
    new_obsv <- orig_new_obsv
    eps <- rnorm(sample_size, mean = 0, sd = violation_func(X))
    return(list(X,new_obsv,eps))
  }
  if (violation_name == "Multicolinearity") {
    X <- unname(cbind(orig_X,violation_func(orig_X)))
    new_obsv<- unname(cbind(orig_new_obsv,violation_func(orig_new_obsv)))
    eps <- rnorm(sample_size, mean = 0, sd = sqrt(sigma_sq))
    return(list(X,new_obsv,eps))
  }
}


# function that will run simulations, violating a specific assumption
run_simulations <- function(num_runs, sample_size, num_new_obsv, violation, violation_func, num_predictors, sigma_sq) {
  
  sim_results <- data.frame(percent_yhat_bad_confint = 0,
                            percent_intercept_bad_confint = 0, 
                            percent_param_bad_confint = 0, 
                            average_mse = 0, 
                            percent_insignificant_intercept = 0, 
                            percent_insignificant_param = 0) 

  parameters <- sample.int(10,num_predictors + 1)
  for (i in 1:num_runs) {
    X <- runif(sample_size, 0, 10)
    new_obsv <- runif(num_new_obsv, 0, 10)
    
    # transform our data to violate assumptions of linearity
    violated_data <- check_violations(sample_size, new_obsv, violation, violation_func, sigma_sq, X)
    violated_X <- violated_data[[1]]
    violated_new_obsv <- violated_data[[2]]
    eps <- violated_data[[3]]
    
    # TODO: make this not break show_diagnostics
    # if (violation == "Multicolinearity") {
    #   X <- violated_X
    #   new_obsv <- violated_new_obsv
    # }
    
    # add in column of ones to capture beta0 when generating Y and expected value of Y
    Y <- (cbind(1,violated_X) %*% parameters) + eps
    exp_val_Y <- cbind(1,violated_new_obsv) %*% parameters
    
    # fit a linear model using the simulated data
    lm_data <- data.frame(Y = Y, X = I(X))
   my_lm <- lm(Y ~ X, data=lm_data)
    
    # predict y for new values of x using the fitted linear model
    Y_hat_ci <- predict(my_lm, newdata = data.frame(X = I(new_obsv)), interval = "confidence")
    
    # check whether the confidence interval actually captures the expected value of y from the true model
    n_bad_predictions <- num_new_obsv - sum((exp_val_Y >= Y_hat_ci[,2]) & (exp_val_Y <= Y_hat_ci[,3]))
# freq of confint for prediction of new data points not capturing the expected val of Y based on ground truth
    sim_results$percent_yhat_bad_confint <- sim_results$percent_yhat_bad_confint + n_bad_predictions
    
    # get confidence iterval for beta hat
    beta_ci <- confint(my_lm)
    
    # check whether the true value for the betas is caputured in the confidence interval
    good_betas <- ((parameters >= beta_ci[,"2.5 %"]) & (parameters <= beta_ci[,"97.5 %"]))
    if (good_betas[1] == FALSE)

# how many times true beta_0 was not captured by the confint for our fitted model
      sim_results$percent_intercept_bad_confint <- sim_results$percent_intercept_bad_confint + 1
    # good_betas[-1] means anything that is not the intercept coeff
    if (sum(good_betas[-1] == FALSE) >= 1) 
# bad predictor rate: how many times a parameter that was not b0 was not within the confint
      # if there's more than one they are combined
      {sim_results$percent_param_bad_confint <- sim_results$percent_param_bad_confint + sum(good_betas[-1] == FALSE)}
    
    # add the mse to the sum of MSE for all runs (to be averaged at the end)
    sim_results$average_mse <- sim_results$average_mse + (anova(my_lm)$'Mean Sq'[2]) # [2] for residual
    
    
    # check which beta_hats are significant based on the p-values
    p_vals <- summary(my_lm)$coeff[,4] # 4 for pvals
    if (p_vals[1] > .05)
# frequency % p-val(intercept) was >0.05      
      sim_results$percent_insignificant_intercept <- sim_results$percent_insignificant_intercept + 1
    if (sum(p_vals[-1] > .05) >= 1)
      
# excluding intercept coeff, freq that params for predictors had p-val > 0.05 in all our sims. on interval (0,1)
      # sum in case more than one predictor var
      {sim_results$percent_insignificant_param <- sim_results$percent_insignificant_param + sum(p_vals[-1] > .05)}
  }
  
  # FINALLY, take mean of all these 
  sim_results <- sim_results/num_runs
  
  # confint for predictions did not capture expected value, divided by n new data points 
  sim_results$percent_yhat_bad_confint <- sim_results$percent_yhat_bad_confint/(num_new_obsv)
  
  # conint for predictor param did not capture true param used to generate data, divited by number of predictors
  sim_results$percent_param_bad_confint <- sim_results$percent_param_bad_confint/(num_predictors)
  
  # precent of (non-intercept) params that whose p-val > 0.05
  sim_results$percent_insignificant_param <- sim_results$percent_insignificant_param/(num_predictors)

  # R is terrible and we have to return our objects as a list >:C
  payload <- list(sim_results=sim_results, lm_model=my_lm, X=X, Y=Y, eps=eps, Y_hat_ci=Y_hat_ci, exp_val_Y=exp_val_Y)
  return(payload)
}
```


```{r show_diagnostics}
show_diagnostics <- function(payload) {
  # unpack payload
  list2env(payload, envir=environment())
  #list[sim_results, lm_model, x, y, eps, y_hat_ci, exp_val_y] <- payload
  
  print(sim_results)
  print("Diagnostic #1: Is the Regression Function Linear? ")
  # print() required inside function
  print(summary(lm_model))
  print(anova(lm_model))
  plot(lm_model)
  # TODO check dims of X before running this so that we don't get an error when plotting a multivariate model
  plot(Y ~ X)

abline(lm_model)
#ggplot(yhat_medsine, aes(x =locations_medsine$x_med, y = fit)) +
#geom_point(size = 4) +
#geom_errorbar(aes(ymax = yhat_medsine$upr, ymin = #yhat_medsine$lwr))

# n_sims <- 1
# n_samps <- 100
# num_new_obsv <- 10
# violation_type <- "Nonlinear relationship"
# violation_func <- sin
# # parameters <- c(0,1)
# num_predictors <- 1
# sigma_sq <- 1
# 
# payload <- run_simulations(n_sims, n_samps, num_new_obsv, violation_type, violation_func, num_predictors, sigma_sq)
# 
# show_diagnostics(payload)

  abline(lm_model)

  print("Diagnostic #2: Do the Residuals Have Constant Variance")
  
  
  
  print("Diagnostic #3: Are the Residuals Normally Distributed?")
  
  
  print("Diagnostic #4: Are the Residuals Independent?")
  
  
   print("Diagnostic #5: Does the model fit all but one or a few outlier observations?")
   
  
}

```

# Questions

1.	Nonlinear relationship
    a.	Simulate data for a variety of different non-linear relationships (e.g. polynomial, exponential, sinusoidal).
    b.	Try simulations with a small sample size (e.g. 20), a medium sample size (e.g. n= 100), and a large sample size (e.g. n = 5000). 
    c.	For each simulation, 
        i.	Predict y-hat at several different locations using a confidence interval.
        ii.	Predict the beta coefficients for a linear model using a confidence interval. 
        iii. Find the MSE (to estimate sigma^2)
        iv. Test to see whether the beta(s) are significant
    d. Which of the above tasks were affected by the nonlinear relationship?  
    e. After you have experimented with the effects of different model structures, true parameter values, and sample sizes, let's repeat the simulation but test yourself to see whether you can detect non-linearity.
        i. Have R randomly choose whether to simulate data from a true linear model or a true nonlinear model.
        ii. Simulate data accordingly and display informal/ formal diagnostics as appropriate.
        iii. Based on the diagnostics, predict whether the problem areas you mentioned in part d will be affected or not. (Note: You are not predicting whether the assumptions are violated-- just whether they are violated to such an extent that your ability to use the model is compromised)  



  We predict that the smaller models will be more likely to be affected by a nonlinear relationship. With large sample sizes, the normality assumption is not critical unless you are predicting new observations. But with smaller sample sizes, a violation of nonnomrality is more likely to affect the model. And since we only have 10 observations in the smaller simluation, the nonnormality assumption is especially difficult to detect because we expect random variation in small sample sizes anyways.  


```{r}
# n_sims <- 100
# n_samps <- 100
# num_new_obsv <- 10
# violation_type <- "Nonlinear relationship"
# violation_func <- sin
# num_predictors <- 1
# sigma_sq <- 1
# 
# payload <- run_simulations(n_sims, n_samps, num_new_obsv, violation_type, violation_func, num_predictors, sigma_sq)
# cat(violation_type, n_sims, n_samps, num_new_obsv, str(violation_func), num_predictors, sigma_sq)
# show_diagnostics(payload)
```
        
__Aside:__ Many of the issues you end up facing with a nonlinear relationship can also be seen if an important predictor is excluded from the model. If you have extra time, feel free to play with this issue as well (optional).


```{r set_up_sim_constants}
# set up constants for simulations
set.seed(1)
n_small <- 20
n_med <- 100
n_large <- 5000
num_runs <- 100
num_new_obsv <- 20
num_predictors <- 1
sigma_sq <- 4
```

## **POLYNOMIAL**
```{r polynomial_relationship}
poly_func <- function(x) (x-5)^2
poly_small_results <- run_simulations(num_runs,
                                      n_small, 
                                      num_new_obsv, 
                                      violation = "Nonlinear relationship", 
                                      violation_func = poly_func, 
                                      num_predictors, 
                                      sigma_sq)

poly_med_results <-run_simulations(num_runs,
                                   n_med, 
                                   num_new_obsv, 
                                   violation =  "Nonlinear relationship", 
                                   violation_func = poly_func, 
                                   num_predictors, 
                                   sigma_sq)

poly_large_results <- run_simulations(num_runs, 
                                     n_large, 
                                     num_new_obsv, 
                                     violation =  "Nonlinear relationship", 
                                     violation_func = poly_func, 
                                     num_predictors, 
                                     sigma_sq)
```

## **EXPONENTIAL**
```{r exponential_relationship}
exp_small_results <- run_simulations(num_runs,
                                     n_small, 
                                     num_new_obsv, 
                                     violation =  "Nonlinear relationship", 
                                     violation_func = exp, 
                                     num_predictors, 
                                     sigma_sq)

exp_med_results <-run_simulations(num_runs, 
                                  n_med, 
                                  num_new_obsv, 
                                  violation =  "Nonlinear relationship",
                                  violation_func = exp, 
                                  num_predictors, 
                                  sigma_sq)

exp_large_results <-run_simulations(num_runs,
                                    n_large, 
                                    num_new_obsv, 
                                    violation =  "Nonlinear relationship", 
                                    violation_func = exp, 
                                    num_predictors, 
                                    sigma_sq)
```

## **SINUSOIDAL**
```{r sinusoidal_relationship}
sin_small_results <- run_simulations(num_runs, 
                                     n_small, 
                                     num_new_obsv, 
                                     violation =  "Nonlinear relationship", 
                                     violation_func = sin, 
                                     num_predictors, 
                                     sigma_sq)

sin_med_results <- run_simulations(num_runs, 
                                   n_med, 
                                   num_new_obsv, 
                                   violation =  "Nonlinear relationship", 
                                   violation_func = sin, 
                                   num_predictors, 
                                   sigma_sq)

sin_large_results <- run_simulations(num_runs, 
                                     n_large, 
                                     num_new_obsv, 
                                     violation =  "Nonlinear relationship", 
                                     violation_func = sin, 
                                     num_predictors, 
                                     sigma_sq)
```

## **LOGARITHMIC**
```{r logarithmic_relationship}
log_small_results <- run_simulations(num_runs, 
                                     n_small, 
                                     num_new_obsv, 
                                     violation =  "Nonlinear relationship", 
                                     violation_func = log,
                                     num_predictors, 
                                     sigma_sq)

log_med_results <- run_simulations(num_runs, 
                                   n_med, 
                                   num_new_obsv, 
                                   violation =  "Nonlinear relationship", 
                                   violation_func = log, 
                                   num_predictors, 
                                   sigma_sq)

log_large_results <- run_simulations(num_runs, 
                                     n_large, 
                                     num_new_obsv, 
                                     violation =  "Nonlinear relationship", 
                                     violation_func = log, 
                                     num_predictors, 
                                     sigma_sq)

```


## PART E
TODO write interpretation
```{r}
#part e, name the normal func & nonnormal func & randomly call it
random.func1 <- sample(c(poly_func, sin, exp, log), 1)

n <- sample(20:5000, 1)
random.violation1 <- sample(c("None","Nonlinear relationship"), 1)

random_results1 <- run_simulations(num_runs, 
                                  n, 
                                  num_new_obsv, 
                                  violation =  random.violation1,
                                  violation_func = random.func1,
                                  num_predictors, 
                                  sigma_sq)
random_results1[[1]]
```


```{r}
show_diagnostics(random_results1)
```


2.	Non-normal errors
    a.	Simulate errors from a variety of different non-normal distributions (e.g. gamma, poisson). Make sure to shift the errors over so that they are still centered at 0.
    b.	Try simulations with a small sample size (e.g. 20), a medium sample size (e.g. n= 100), and a large sample size (e.g. n = 5000). 
    c.	For each simulation, 
        i.	Predict y-hat at several different locations using a confidence interval.
        ii.	Predict the beta coefficients for a linear model using a confidence interval. 
        iii. Find the MSE (to estimate sigma^2)
        iv. Test to see whether the beta(s) are significant (t-tests)
    d. Which of the above tasks were affected by the violation of assumptions?
    e. After you have experimented with the effects of different model structures, true parameter values, and sample sizes, let's repeat the simulation but test yourself to see whether you can detect non-normality.
        i. Have R randomly choose whether to simulate data with normal or nonnormal errors
        ii. Simulate data accordingly and display informal/ formal diagnostics as appropriate.
        iii. Based on the diagnostics, predict whether the problem areas you mentioned in part d will be affected or not. (Note: You are not predicting whether the assumptions are violated-- just whether they are violated to such an extent that your ability to use the model is compromised)

## **GAMMA**
```{r gamma_errors}
gamma_small_results <- run_simulations(num_runs, 
                                     n_small, 
                                     num_new_obsv, 
                                     violation =  "Non-normal errors", 
                                     violation_func = "Gamma",
                                     num_predictors, 
                                     sigma_sq)

gamma_med_results <- run_simulations(num_runs, 
                                   n_med, 
                                   num_new_obsv, 
                                   violation =  "Non-normal errors", 
                                   violation_func = "Gamma", 
                                   num_predictors, 
                                   sigma_sq)

gamma_large_results <- run_simulations(num_runs, 
                                     n_large, 
                                     num_new_obsv, 
                                     violation =  "Non-normal errors", 
                                     violation_func = "Gamma", 
                                     num_predictors, 
                                     sigma_sq)


```


## **POISSON**
```{r poisson_errors}
poisson_small_results <- run_simulations(num_runs, 
                                     n_small, 
                                     num_new_obsv, 
                                     violation =  "Non-normal errors", 
                                     violation_func = "Poisson",
                                     num_predictors, 
                                     sigma_sq)

poisson_med_results <- run_simulations(num_runs, 
                                   n_med, 
                                   num_new_obsv, 
                                   violation =  "Non-normal errors", 
                                   violation_func = "Poisson", 
                                   num_predictors, 
                                   sigma_sq)

poisson_large_results <- run_simulations(num_runs, 
                                     n_large, 
                                     num_new_obsv, 
                                     violation =  "Non-normal errors", 
                                     violation_func = "Poisson", 
                                     num_predictors, 
                                     sigma_sq)

```


## PART D
# TODO talk about sim results table
```{r}
(polynomial_results <- rbind(small_samp = poly_small_results[[1]], 
                            med_samp = poly_med_results[[1]], 
                            large_samp = poly_large_results[[1]]))

(exponential_results <- rbind(small_samp = exp_small_results[[1]],
                             med_samp = exp_med_results[[1]], 
                             large_samp = exp_large_results[[1]]))

(sinusoidal_results <- rbind(small_samp = sin_small_results[[1]], 
                            med_samp = sin_med_results[[1]], 
                            large_samp = sin_large_results[[1]]))

(logarithmic_results <- rbind(small_samp = log_small_results[[1]], 
                             med_samp = log_med_results[[1]], 
                             large_samp = log_large_results[[1]]))

(gamma_results <- rbind(small_samp = gamma_small_results[[1]], 
                             med_samp = gamma_med_results[[1]], 
                             large_samp = gamma_large_results[[1]]))

(poisson_results <- rbind(small_samp = poisson_small_results[[1]], 
                             med_samp = poisson_med_results[[1]], 
                             large_samp = poisson_large_results[[1]]))
```


## PART E
TODO write interpretation

```{r}
#part e, name the normal func & nonnormal func & randomly call it
random.func2 <- sample(c("Poisson","Gamma"), 1)
n <- sample(20:5000, 1)
random.violation2 <- sample(c("None","Non-normal errors"), 1)

random_results2 <- run_simulations(num_runs, 
                                  n, 
                                  num_new_obsv, 
                                  violation =  random.violation2,
                                  violation_func = random.func2,
                                  num_predictors, 
                                  sigma_sq)

random_results2[[1]]
```


```{r}
show_diagnostics(random_results2)
```

3. Heterogeneous Variances
    a.	Simulate errors from a variety of different relationships with X (e.g. eps = 2 * sqrt(x))
    b.	Try simulations with a small sample size (e.g. 20), a medium sample size (e.g. n= 100), and a large sample size (e.g. n = 5000). 
    c.	For each simulation, 
        i.	Predict y-hat at several different locations using a confidence interval.
        ii.	Predict the beta coefficients for a linear model using a confidence interval. 
        iii. Find the MSE (to estimate sigma^2-- does that even make sense here?)
        iv. Test to see whether the beta(s) are significant (t-tests)
    d. Which of the above tasks were affected by the violation of assumptions?
    e. After you have experimented with the effects of different model structures, true parameter values, and sample sizes, let's repeat the simulation but test yourself to see whether you can detect heteroskedacity.
        i. Have R randomly choose whether to simulate errors with constant or non-constant variance
        ii. Simulate data accordingly and display informal/ formal diagnostics as appropriate.
        iii. Based on the diagnostics, predict whether the problem areas you mentioned in part d will be affected or not. (Note: You are not predicting whether the assumptions are violated-- just whether they are violated to such an extent that your ability to use the model is compromised)
        
```{r}
# Sample code to get started
# n <- 200
# b0 <- 10
# b1 <- 10
# 
# x <- runif(n, 0, 10)
# eps <- rnorm(n, sd = 0.5 * x^2)
# y <- b0 + b1 * x + eps

```

```{r}
hetero_var_small_results <- run_simulations(num_runs,
                                     n_small, 
                                     num_new_obsv, 
                                     violation =  "Heterogeneous variances", 
                                     violation_func = poly_func, 
                                     num_predictors, 
                                     sigma_sq)

hetero_var_med_results <-run_simulations(num_runs, 
                                  n_med, 
                                  num_new_obsv, 
                                  violation =  "Heterogeneous variances",
                                  violation_func = poly_func, 
                                  num_predictors, 
                                  sigma_sq)

hetero_var_large_results <-run_simulations(num_runs,
                                    n_large, 
                                    num_new_obsv, 
                                    violation =  "Heterogeneous variances", 
                                    violation_func = poly_func, 
                                    num_predictors, 
                                    sigma_sq)

hetero_var_results <- rbind(small_samp = hetero_var_small_results,
                             med_samp = hetero_var_med_results, 
                             large_samp = hetero_var_large_results)
hetero_var_results
```


## PART E
TODO write interpretation

```{r}
#part e, name the normal func & nonnormal func & randomly call it
random_poly_func <- function(x) {
  a <- runif(1,0,5)
  b <- runif(1,2,4)
  (x-a)^b
}
random.func3 <- sample(c(random_poly_func, exp), 1)
n <- sample(20:5000, 1)
random.violation3 <- sample(c("None","Heterogeneous variances"), 1)

random_results3 <- run_simulations(num_runs, 
                                  n, 
                                  num_new_obsv, 
                                  violation =  random.violation3,
                                  violation_func = random.func3,
                                  num_predictors, 
                                  sigma_sq)

random_results3[[1]]
```

```{r}
show_diagnostics(random_results3)
```


4. Correlated Errors
    a.	Simulate errors from a variety of different correlation structures.
    b.	Try simulations with a small sample size (e.g. 20), a medium sample size (e.g. n= 100), and a large sample size (e.g. n = 5000). 
    c.	For each simulation, 
        i.	Predict y-hat at several different locations using a confidence interval.
        ii.	Predict the beta coefficients for a linear model using a confidence interval. 
        iii. Find the MSE (to estimate sigma^2)
        iv. Test to see whether the beta(s) are significant (t-tests)
    d. Which of the above tasks were affected by the violation of assumptions?
    e. After you have experimented with the effects of different model structures, true parameter values, and sample sizes, let's repeat the simulation but test yourself to see whether you can detect correlated errors.
        i. Have R randomly choose whether to simulate data with correlated or uncorrelated errors.
        ii. Simulate data accordingly and display informal/ formal diagnostics as appropriate.
        iii. Based on the diagnostics, predict whether the problem areas you mentioned in part d will be affected or not. (Note: You are not predicting whether the assumptions are violated-- just whether they are violated to such an extent that your ability to use the model is compromised)

```{r}
# Sample code to get started
n <- 200
b0 <- 10
b1 <- 10
rho <- 0.9
sigma <- 2

x <- runif(n, 0, 10)

eps <- arima.sim(model = list(ar = rho), n = n)

y <- b0 + b1 * x + eps

# OR...

eps <- rep(0, n)
e.ind <- rnorm(n, mean = 0, sd = (sigma / sqrt(1-rho^2)))
eps[1] <- e.ind[1]
for (i in 2:n) {
  eps[i] <- rho * eps[i-1] + e.ind[i]
}

y <- b0 + b1 * x + eps
```
        
5. Multicollinearity
    a.	Simulate predictors that are correlated with a variety of different correlation structures
    b.	Try simulations with a small sample size (e.g. 20), a medium sample size (e.g. n= 100), and a large sample size (e.g. n = 5000). 
    c.	For each simulation, 
        i.	Predict y-hat at several different locations using a confidence interval.
        ii.	Predict the beta coefficients for a linear model using a confidence interval. 
        iii. Find the MSE (to estimate sigma^2)
        iv. Test to see whether the beta(s) are significant (t-tests)
    d. Which of the above tasks were affected by the violation of assumptions?  
    The simulation with the largest sample size was most affected by the violation of the assumptions. This makes sense since moderate multicollinearity should not really affect the model.  
    e. After you have experimented with the effects of different model structures, true parameter values, and sample sizes, let's repeat the simulation but test yourself to see whether you can detect collinearity.
        i. Have R randomly choose whether to simulate data with correlated or uncorrelated predictor variables (X).
        ii. Simulate data accordingly and display informal/ formal diagnostics as appropriate.
        iii. Based on the diagnostics, predict whether the problem areas you mentioned in part d will be affected or not. (Note: You are not predicting whether the assumptions are violated-- just whether they are violated to such an extent that your ability to use the model is compromised)
        
```{r}
# add_noise <- function(x) x + rnorm(length(x))
# num_predictors <- 2
# multicolinearity_small_results <- run_simulations(num_runs,
#                                      n_small, 
#                                      num_new_obsv, 
#                                      violation =  "Multicolinearity", 
#                                      violation_func = add_noise, 
#                                      num_predictors, 
#                                      sigma_sq)
# 
# multicolinearity_med_results <- run_simulations(num_runs,
#                                      n_med, 
#                                      num_new_obsv, 
#                                      violation =  "Multicolinearity", 
#                                      violation_func = add_noise, 
#                                      num_predictors, 
#                                      sigma_sq)
# 
# multicolinearity_large_results <- run_simulations(num_runs,
#                                      n_large, 
#                                      num_new_obsv, 
#                                      violation =  "Multicolinearity", 
#                                      violation_func = add_noise, 
#                                      num_predictors, 
#                                      sigma_sq)
# 
# multicolinearity_results <- rbind(small_samp = multicolinearity_small_results,
#                              med_samp = multicolinearity_med_results, 
#                              large_samp = multicolinearity_large_results)
# multicolinearity_results
```


## PART E
TODO write interpretation
```{r}
#part e, name the normal func & nonnormal func & randomly call it
n <- sample(20:5000, 1)
random.violation5 <- sample(c("None","Multicolinearity"), 1)

random_results5 <- run_simulations(num_runs, 
                                  n, 
                                  num_new_obsv, 
                                  violation =  random.violation5,
                                  violation_func = add_noise,
                                  num_predictors, 
                                  sigma_sq)

random_results5[[1]]
```

```{r}
show_diagnostics(random_results5)
```
    

```{r}
# B <- 100
# many.sims.multicollinearity <- sapply(1:B, function(i) {
#     # x <- rnorm(100, mean = 0, sd = 1)
#     # eps <- rnorm(100, mean = 0, sd = sqrt(0.25))
#     # y <- -1 + 0.5 * x + eps
#     # simul.fit <- lm(y ~ x)
#     # beta.1 <- 0.5
#     # lower <- confint(simul.fit, "x")[1]
#     # upper <- confint(simul.fit, "x")[2]
#     # boolean <- beta.1 <= upper & beta.1 >= lower
#     #return(boolean)
# })

# proportion <- sum(many.sims.multicollinearity)/length(many.sims.multicollinearity)
# proportion

```

<!-- r proportion % of my confidence intervals capture the true value of  .    -->

        
6. Put it all together: Combine the code from the previous 5 parts. Have R randomly choose whether to generate data that violates one (or more) of the assumptions, or whether all the assumptions are valid. Show appropriate diagnostics and test yourself to see if you can predict whether there are problem areas or not. Repeat the simulation several times and record your accuracy at detecting the different problem areas.  


```{r}



```

